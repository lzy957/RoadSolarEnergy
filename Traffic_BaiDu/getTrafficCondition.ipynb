{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import sys  \n",
    "\n",
    "\n",
    "with open('/datadrive/urbanplayground/Streetview/Traffic/CD/cdtraffic.csv', 'w', newline='') as f:\n",
    "\twriter = csv.writer(f)\n",
    "\twith open('/datadrive/urbanplayground/Streetview/Traffic/CD/201904175.csv', 'r') as sdata:\n",
    "\t\tsreader = csv.reader(sdata)\n",
    "\t\tfor srow in sreader:\n",
    "\t\t\ti=sreader.line_num-1\n",
    "\t\t\tprint(i)\n",
    "\t\t\tfor filenum in range(5,21):\n",
    "\t\t\t\tfilepath='/datadrive/urbanplayground/Streetview/Traffic/CD/20190417'+str(filenum)+'.csv' \n",
    "\t\t\t\twith open(filepath, 'r') as data:\n",
    "\t\t\t\t\tlines = data.readlines()\n",
    "\t\t\t\t\t# Get coordinate\n",
    "\t\t\t\t\t#cspeed=lines[i].rstrip('\\r').split(',')[5]\n",
    "\t\t\t\t\tffspeed=lines[i].rstrip('\\r').split(',')[5]\n",
    "\t\t\t\t\t#i=i+2\n",
    "\t\t\t\t\tffspeed=ffspeed.strip('\\t\\r\\n')\n",
    "\t\t\t\t\t#srow.append(cspeed)\n",
    "\t\t\t\t\tsrow.append(ffspeed)\n",
    "\t\t\tfor filenum in range(5,21):\n",
    "\t\t\t\tfilepath='/datadrive/urbanplayground/Streetview/Traffic/CD/20190420'+str(filenum)+'.csv' \n",
    "\t\t\t\twith open(filepath, 'r') as data:\n",
    "\t\t\t\t\tlines = data.readlines()\n",
    "\t\t\t\t\t# Get coordinate\n",
    "\t\t\t\t\t#cspeed=lines[i].rstrip('\\r').split(',')[5]\n",
    "\t\t\t\t\tffspeed=lines[i].rstrip('\\r').split(',')[5]\n",
    "\t\t\t\t\t#i=i+2\n",
    "\t\t\t\t\tffspeed=ffspeed.strip('\\t\\r\\n')\n",
    "\t\t\t\t\t#srow.append(cspeed)\n",
    "\t\t\t\t\tsrow.append(ffspeed)\n",
    "\t\t\twriter.writerow(srow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import time\n",
    "\n",
    "with open(\"./bjtraffic.csv\",'rt',encoding='UTF-8') as raw_data:\n",
    "    readers=csv.reader(raw_data,delimiter=',')\n",
    "    x=list(readers)\n",
    "    traffic=np.array(x)\n",
    "    pt = np.loadtxt(\"./BJPtDB.csv\",dtype=np.str,delimiter=',',encoding='utf-8')\n",
    "    with open('./BJ.csv', 'w') as fileWriteObj:\n",
    "        roadidt = pt[0][6]\n",
    "        count = 0\n",
    "        lcount = 0\n",
    "        for j in range(0,pt.size):\n",
    "            #print(pt[j])\n",
    "            time.sleep(1)\n",
    "            row = []\n",
    "            roadid = pt[j][6]\n",
    "            num = pt[j][0]\n",
    "            road_type = pt[j][8]\n",
    "            lng = pt[j][4]\n",
    "            lat = pt[j][5]\n",
    "            dem = pt[j][8]\n",
    "            slope = pt[j][9]\n",
    "            aspect = pt[j][10]\n",
    "            #print(\"j num\")\n",
    "            #print(j,num)\n",
    "            row = [num,roadidt,road_type,lng,lat,dem,slope,aspect]\n",
    "            if roadid != roadidt:\n",
    "                #print(\"unequal\")\n",
    "                #print(num,traffic[lcount][0])\n",
    "                count = 1\n",
    "                if num != traffic[lcount][0]:\n",
    "                    lcount += 1\n",
    "                roadidt = roadid \n",
    "            else:\n",
    "                # print(\"equal\")\n",
    "                count += 1\n",
    "            if count%3 == 0:\n",
    "                #print(lcount,traffic[lcount][0])\n",
    "                for i in range(5,len(traffic[lcount])):\n",
    "                    if(traffic[lcount][i]==-1):\n",
    "                        row.append(1)\n",
    "                    else:\n",
    "                        row.append((100.0-float(traffic[lcount][i]))/100.0)\n",
    "                lcount += 1\n",
    "            else:\n",
    "                #print(lcount,traffic[lcount][0])\n",
    "                for i in range(5,len(traffic[lcount])):\n",
    "                    if(traffic[lcount][i]==-1):\n",
    "                        row.append(1)\n",
    "                    else:\n",
    "                        row.append((100.0-float(traffic[lcount][i]))/100.0)\n",
    "            writer = csv.writer(fileWriteObj, lineterminator='\\n')\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 736629 entries, 0 to 736628\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   fid     736629 non-null  int64  \n",
      " 1   r_id    736629 non-null  int64  \n",
      " 2   r_type  736629 non-null  object \n",
      " 3   log     736629 non-null  float64\n",
      " 4   lat     736629 non-null  float64\n",
      " 5   pr_id   736629 non-null  int64  \n",
      "dtypes: float64(2), int64(3), object(1)\n",
      "memory usage: 33.7+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 208724 entries, 0 to 208723\n",
      "Data columns (total 20 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   fid             208724 non-null  int64  \n",
      " 1   roadid          208724 non-null  int64  \n",
      " 2   roadtype        0 non-null       float64\n",
      " 3   lat             208724 non-null  float64\n",
      " 4   lng             208724 non-null  float64\n",
      " 5   edm             208724 non-null  float64\n",
      " 6   slope           197074 non-null  float64\n",
      " 7   aspect          208724 non-null  float64\n",
      " 8   dir_nt          208724 non-null  float64\n",
      " 9   dir_work        208724 non-null  float64\n",
      " 10  dir_wkend       208724 non-null  float64\n",
      " 11  dir_weighted    208724 non-null  float64\n",
      " 12  dif_nt          208724 non-null  float64\n",
      " 13  dif_work        208724 non-null  float64\n",
      " 14  dif_wkend       208724 non-null  float64\n",
      " 15  dif_weighted    208724 non-null  float64\n",
      " 16  total_nt        208724 non-null  float64\n",
      " 17  total_work      208724 non-null  float64\n",
      " 18  total_wkend     208724 non-null  float64\n",
      " 19  total_weighted  208724 non-null  float64\n",
      "dtypes: float64(18), int64(2)\n",
      "memory usage: 31.8 MB\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './BaiduAK.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-1f7ed2ad90ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m     \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mSpider\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m     \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Spider run finish\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-1f7ed2ad90ca>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups_q\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlenth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups_q\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maks_q\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_aks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_q\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQueue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-1f7ed2ad90ca>\u001b[0m in \u001b[0;36mget_aks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_aks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./BaiduAK.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0mapilines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0maks_q\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQueue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './BaiduAK.txt'"
     ]
    }
   ],
   "source": [
    "import requests, json\n",
    "from queue import Queue\n",
    "from threading import Thread\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time, random\n",
    "import traceback\n",
    "import csv\n",
    "import math\n",
    "\n",
    "class Spider():\n",
    "    def __init__(self):\n",
    "        self.thread_num = 4\n",
    "        self.city = 'BJ'\n",
    "        self.listall = []\n",
    "        self.start = time.time()\n",
    "        self.groups_q = self.get_points()\n",
    "        self.lenth = self.groups_q.qsize()\n",
    "        self.aks_q = self.get_aks()\n",
    "        self.valid_q = Queue()\n",
    "\n",
    "    def get_aks(self):\n",
    "        with open(\"/datadrive/lzy/Traffic/BaiduAK.txt\", 'r', encoding='utf8') as f:\n",
    "            apilines = f.readlines()\n",
    "        aks_q = Queue()\n",
    "        for ak in apilines:\n",
    "            aks_q.put(ak)\n",
    "        return aks_q\n",
    "    \n",
    "    def split_list(self, l, n=100):\n",
    "        # 均分列表\n",
    "        new_l = []\n",
    "        for i in range(0,len(l),n):\n",
    "            new_l.append(l[i:i+n])\n",
    "        new_l.append(l[int(len(l)/n)*n:])\n",
    "        return new_l\n",
    "    \n",
    "    def get_points(self):\n",
    "        df_p = pd.read_csv('/datadrive/lzy/Traffic/'+ self.city +'/'+ self.city +'AllPoints.csv')\n",
    "        df_p.rename(columns={'p_id':'fid'},inplace=True)\n",
    "        df_p.info()\n",
    "        df_R = pd.read_csv('/datadrive/lzy/R/'+ self.city +'BSV_r.csv')\n",
    "        df_R.info()\n",
    "        df=pd.merge(df_p,df_R,on = 'fid',how='right')\n",
    "        groups_q = Queue()\n",
    "        groups = np.array(df.iloc[:,[0,3,4]]).tolist()\n",
    "        point_groups = self.split_list(groups)\n",
    "        for group in point_groups:\n",
    "            groups_q.put(group)\n",
    "        return groups_q\n",
    "    \n",
    "    def TileCoord(self,point,zoom):\n",
    "        pointx,pointy = point.split(\",\")\n",
    "        Xtemp = float(pointx)* math.pow(2,zoom - 18)\n",
    "        Ytemp = float(pointy)* math.pow(2,zoom - 18)\n",
    "        # print(Xtemp,Ytemp)\n",
    "        tileX = math.floor(Xtemp / 256)\n",
    "        tileY = math.floor(Ytemp / 256)\n",
    "        pixelX = Xtemp - tileX * 256\n",
    "        pixelY = Ytemp - tileY * 256\n",
    "        return [tileX, tileY, pixelX, pixelY]\n",
    "\n",
    "\n",
    "    def req(self, group):\n",
    "        coordids = []\n",
    "        w84c = []\n",
    "        for point in group:\n",
    "            coordids.append(point[0])\n",
    "            lon = point[1]\n",
    "            lat = point[2]                   \n",
    "            # 之前返回的结果里的 XY 坐标是*100的，所以这里要缩放一下\n",
    "            w84c.append(\"{},{}\".format(lon, lat))\n",
    "        # 访问 url 直到得到正确的访问结果\n",
    "        while True:\n",
    "            time.sleep(random.random()*2)\n",
    "            ak = self.aks_q.get()\n",
    "            ak = ak.strip('\\t\\r\\n')\n",
    "            data = {\n",
    "                \"ak\": ak,\n",
    "                \"coords\": \"{}\".format(\";\".join(w84c)),\n",
    "                \"from\": \"1\",\n",
    "                \"to\": \"6\",\n",
    "                }\n",
    "            data2 = {\n",
    "                \"ak\": ak,\n",
    "                \"coords\": \"{}\".format(\";\".join(w84c)),\n",
    "                \"from\": \"1\",\n",
    "                \"to\": \"5\",\n",
    "                }\n",
    "            try:\n",
    "                # request coordinations\n",
    "                r = requests.get(\"http://api.map.baidu.com/geoconv/v1/?\", params=data,timeout=60)\n",
    "                r.encoding='utf-8'\n",
    "                data = r.json()\n",
    "                print(ak)\n",
    "                r2 = requests.get(\"http://api.map.baidu.com/geoconv/v1/?\", params=data2,timeout=60)\n",
    "                r2.encoding='utf-8'\n",
    "                data2 = r2.json()\n",
    "                # print(data[\"status\"],data2[\"status\"])\n",
    "                if data[\"status\"] == 0 and data2[\"status\"]==0:\n",
    "                    # 把有用的 ak 放回队列\n",
    "                    self.aks_q.put(ak)\n",
    "                    for i in range(len(data[\"result\"])):\n",
    "                        #print(i,coordids[i],w84c[i],data[\"result\"][i][\"x\"],data[\"result\"][i][\"y\"],data2[\"result\"][i][\"x\"],data2[\"result\"][i][\"y\"])\n",
    "                        self.valid_q.put({\n",
    "                            \"coordid\": coordids[i],\n",
    "                            \"w84c\": w84c[i],\n",
    "                            \"bd09mc\": \"{},{}\".format(data[\"result\"][i][\"x\"],data[\"result\"][i][\"y\"]),\n",
    "                            \"bd09ll\": \"{},{}\".format(data2[\"result\"][i][\"x\"],data2[\"result\"][i][\"y\"])\n",
    "                        })\n",
    "                    break\n",
    "                else:\n",
    "                    print(data)\n",
    "            except Exception as e:\n",
    "                # print(\"\\n Error: \", repr(e))\n",
    "                traceback.print_exc()\n",
    "\n",
    "    # 线程1： 访问 url 获取结果\n",
    "    def producer(self):\n",
    "        while self.groups_q.empty() is False:\n",
    "            group = self.groups_q.get()\n",
    "            self.req(group)\n",
    "    \n",
    "    # 线程2：将线程1的结果存入数据库\n",
    "    def write(self):\n",
    "        with open(r'/datadrive/lzy/Traffic/'+ self.city +'/'+ self.city +'Coordall.csv', 'w') as fileWriteObj:\n",
    "            writer = csv.writer(fileWriteObj, lineterminator='\\n')\n",
    "            writer.writerow(['id','w84c','bd09mc','bd09ll','19_Tilex','19_Tiley','19_Pixelx','19_Pixely'])\n",
    "            while (self.groups_q.empty() is False) or (self.valid_q.empty() is False):\n",
    "                list_data = []\n",
    "                if self.valid_q.empty() is False:\n",
    "                    #print(\"write get\\n\")\n",
    "                    data = self.valid_q.get()\n",
    "                    list_data =  [data['coordid'], data['w84c'], data['bd09mc'], data['bd09ll']]\n",
    "                    tileC = self.TileCoord(list_data[2],19)\n",
    "                    list_data = list_data + tileC\n",
    "                    # list_data =  [[_data['coordid'], _data['w84c'], _data['bd09mc'], _data['bd09ll']] for _data in data]\n",
    "                    # list_data =  [[_data[0], _data[1], _data[2], _data[3]] for _data in data]\n",
    "                    writer.writerow(list_data)\n",
    "                    self.listall.append(list_data)\n",
    "                #print(len(self.listall))\n",
    "        print(\"run finish\")\n",
    "        print(len(self.listall))\n",
    "#         name=['id','w84c','bd09mc','bd09ll']\n",
    "#         test=pd.DataFrame(columns=name,data=self.listall)#数据有三列，列名分别为one,two,three\n",
    "#         test.info()\n",
    "#         test.to_csv('/datadrive/lzy/Traffic/TM/TMCoord1.csv',encoding='utf-8')\n",
    "    \n",
    "    # 线程3： 进度条显示\n",
    "    def pbar(self):\n",
    "        state = [0, 0]\n",
    "        while (self.groups_q.empty() is False) or (self.valid_q.empty() is False) :\n",
    "            if [self.lenth-self.groups_q.qsize(), self.valid_q.qsize()] != state:\n",
    "                state = [self.lenth-self.groups_q.qsize(), self.valid_q.qsize()]\n",
    "                print(\"Processing: {}/{}, time elapse: {:.0f}s, waiting for update: {}\".format(self.lenth-self.groups_q.qsize(), self.lenth, time.time()-self.start, self.valid_q.qsize()))\n",
    "                time.sleep(1)\n",
    "                \n",
    "    def run(self):\n",
    "        ths =[]\n",
    "\n",
    "        pbar_thread = Thread(target=self.pbar)\n",
    "        pbar_thread.start()\n",
    "        ths.append(pbar_thread)\n",
    "        \n",
    "        for _ in range(self.thread_num):\n",
    "            producer_thread = Thread(target=self.producer)\n",
    "            producer_thread.start()\n",
    "            ths.append(producer_thread)\n",
    "\n",
    "        write_thread = Thread(target=self.write)\n",
    "        write_thread.start()\n",
    "        ths.append(write_thread)\n",
    "\n",
    "        # 阻塞主线程\n",
    "        for th in ths:\n",
    "            th.join()\n",
    "        \n",
    "        print(\"Time consume:\", time.time()-self.start, \"s\")  \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    text= Spider()\n",
    "    text.run()\n",
    "    print(\"Spider run finish\")\n",
    "    print(text.listall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: 368676/368676, time elapse: 253899s, waiting for imgprocess:49017131, waiting for get traffic from img: 0\n",
      "Processing: 368676/368676, time elapse: 253904s, waiting for imgprocess:49017131, waiting for get traffic from img: 0\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "from queue import Queue\n",
    "from threading import Thread\n",
    "import requests, urllib3\n",
    "import sys, traceback\n",
    "import time, os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import cv2\n",
    "from skimage.morphology import disk\n",
    "import skimage.filters.rank as sfr\n",
    "import math\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "class Spider():\n",
    "    def __init__(self):\n",
    "        self.city = 'BJ'\n",
    "        self.thread_num = 1\n",
    "        self.start = time.time()\n",
    "        self.zoom = 19\n",
    "        # 各种队列\n",
    "        #self.trafficxy_q = self.get_trafficxys()# bd09mc坐标队列\n",
    "        #self.TileCoord_q = self.coordTrans()# bd09mc与瓦片地图坐标转换后队列\n",
    "        self.TileCoord_q = self.get_coordTrans()# bd09mc与瓦片地图坐标转换后队列\n",
    "        self.all_lenth = self.TileCoord_q.qsize() # 队列总长度\n",
    "        self.trafficimg_q = Queue() # traffic image queue to process\n",
    "        self.finish_q = Queue() # 已经确认的队列\n",
    "        #self.ippool_q = Queue() # 代理池队列\n",
    "        for day in range(0,7):\n",
    "            for hour in range(4,23):\n",
    "                rootpath = \"/datadrive/lzy/Traffic/\"+self.city+\"/\"+self.city+\"TrafficImg{0}_{1}\".format(day,hour)\n",
    "                rootpath_g = \"/datadrive/lzy/Traffic/\"+self.city+\"/\"+self.city+\"TrafficImg{0}_{1}_graymin\".format(day,hour)\n",
    "                if not os.path.exists(rootpath):\n",
    "                    os.mkdir(rootpath)\n",
    "                if not os.path.exists(rootpath_g):\n",
    "                    os.mkdir(rootpath_g)\n",
    "        \n",
    "\n",
    "    def get_trafficxys(self):\n",
    "        df = pd.read_csv('/datadrive/lzy/Traffic/'+self.city+\"/\"+self.city+'Coord.csv')\n",
    "        trafficxy_q = Queue()\n",
    "        groups = np.array(df.iloc[:,[0,2]]).tolist()\n",
    "        for group in groups:\n",
    "            #print(group)\n",
    "            trafficxy_q.put(group)\n",
    "        return trafficxy_q\n",
    "\n",
    "    \n",
    "    def get_coordTrans(self):\n",
    "        df_p = pd.read_csv('/datadrive/lzy/Traffic/'+self.city+\"/\"+self.city+'Coordall.csv')\n",
    "        df_p.rename(columns={'id':'fid'},inplace=True)\n",
    "        df_R = pd.read_csv('/datadrive/lzy/R/'+ self.city +'BSV_r.csv')\n",
    "        df=pd.merge(df_p,df_R,on = 'fid',how='right')\n",
    "        TileCoord_q = Queue()\n",
    "        groups = np.array(df.iloc[:,[0,4,5,6,7]]).tolist()\n",
    "        for group in groups:\n",
    "            #print(group)\n",
    "            TileCoord_q.put(group)\n",
    "        return TileCoord_q\n",
    "    \n",
    "    \n",
    "    def coordTrans(self):\n",
    "        tilecoord_q = Queue()\n",
    "        while self.trafficxy_q.empty() is False:\n",
    "            group = self.trafficxy_q.get()\n",
    "            pointx,pointy = group[1].split(\",\")\n",
    "            Xtemp = float(pointx)* math.pow(2,zoom - 18)\n",
    "            Ytemp = float(pointy)* math.pow(2,zoom - 18)\n",
    "            tileX = math.floor(Xtemp / 256)\n",
    "            tileY = math.floor(Ytemp / 256)\n",
    "            pixelX = Xtemp - tileX * 256\n",
    "            pixelY = Ytemp - tileY * 256\n",
    "            list_data = [group[0],tileX, tileY, pixelX, pixelY]\n",
    "            tilecoord_q.put(list_data)\n",
    "        return tilecoord_q\n",
    "             \n",
    "    \n",
    "    def req(self,day,hour,coord_data):\n",
    "        # 访问 url 直到得到正确的访问结果\n",
    "        #time.sleep(random.random())\n",
    "        data = {\n",
    "            \"level\": self.zoom,\n",
    "            \"x\": coord_data[1],\n",
    "            \"y\": coord_data[2],\n",
    "            \"day\": day,\n",
    "            \"hour\": hour,\n",
    "            \"t\": time.time(),\n",
    "            \"v\": \"081\",\n",
    "            \"smallflow\": 1,\n",
    "            \"scaler\": 1,\n",
    "            }\n",
    "        try:\n",
    "            # request coordinations\n",
    "            r = requests.get(\"https://its.map.baidu.com/traffic/HistoryService?\", params=data,timeout=20)\n",
    "            # url = \"https://sp3.baidu.com/7_AZsjOpB1gCo2Kml5_Y_DAcsMJiwa/traffic/HistoryService?level=19&x=99538&y=27765&day=2&hour=11&t=1608801276170&v=081&smallflow=1&scaler=1\"\n",
    "            r.encoding='utf-8'\n",
    "            rootpath = \"/datadrive/lzy/Traffic/\"+self.city+\"/\"+self.city+\"TrafficImg{0}_{1}\".format(day,hour)\n",
    "            imgpath=\"/{0}_{1}.png\".format(coord_data[1],coord_data[2])\n",
    "            # print(day,hour,coord_data[0],coord_data[1],coord_data[2])\n",
    "            open(rootpath + imgpath, 'wb').write(r.content)\n",
    "            graypath = rootpath+\"_graymin\"+imgpath\n",
    "            if not os.path.exists(graypath):\n",
    "                img = cv2.imread(rootpath+imgpath, cv2.IMREAD_GRAYSCALE)\n",
    "                if img is not None:\n",
    "                    img[img <1] = 255\n",
    "                    imgmin = sfr.minimum(img,disk(10))\n",
    "                    cv2.imwrite(graypath,imgmin)\n",
    "            self.trafficimg_q.put(\"{},{}\".format(rootpath,imgpath))\n",
    "        except Exception as e:\n",
    "            print(\"\\n Error: \", repr(e), coord_data)\n",
    "            traceback.print_exc()\n",
    "\n",
    "                \n",
    "    # 线程1： 访问 url 下载图片\n",
    "    def producer(self):\n",
    "        print(\"producer thread started.\")\n",
    "        while self.TileCoord_q.empty() is False:\n",
    "            coord_data = self.TileCoord_q.get()\n",
    "            threadPool = ThreadPoolExecutor(max_workers=4, thread_name_prefix=\"test_\")\n",
    "            for day in range(0,7):\n",
    "                for hour in range(4,23):\n",
    "                    rootpath = \"/datadrive/lzy/Traffic/\"+self.city+\"/\"+self.city+\"TrafficImg{}_{}\".format(day,hour)\n",
    "                    imgpath = \"/{0}_{1}.png\".format(coord_data[1],coord_data[2])\n",
    "                    if not os.path.exists(rootpath+imgpath):\n",
    "                        threadPool.submit(self.req,day,hour,coord_data)\n",
    "                    else:\n",
    "                        self.trafficimg_q.put(\"{},{}\".format(rootpath,imgpath))\n",
    "            coord_data.append(imgpath)\n",
    "            self.finish_q.put(coord_data)\n",
    "        print(\"producer thread done\")\n",
    "\n",
    "\n",
    "    # 线程2： 更新数据库\n",
    "    def imgprocess(self):\n",
    "        print(\"img processor thread start\\n\")\n",
    "        while (self.trafficimg_q.empty() is False) or (self.TileCoord_q.empty() is False):\n",
    "            if self.trafficimg_q.empty() is False:\n",
    "                path = self.trafficimg_q.get()\n",
    "                rpth,imgpath = path.split(\",\")\n",
    "                graypath = rpth+\"_graymin\"+imgpath\n",
    "                if not os.path.exists(graypath):\n",
    "                    img = cv2.imread(rpth+imgpath, cv2.IMREAD_GRAYSCALE)\n",
    "                    if img is not None:\n",
    "                        img[img <1] = 255\n",
    "                        imgmin = sfr.minimum(img,disk(10))\n",
    "                        cv2.imwrite(graypath,imgmin)\n",
    "        print(\"img processor thread done\")\n",
    "\n",
    "\n",
    "    # 线程3： 爬取代理\n",
    "    def get_traffics(self):\n",
    "        print(\"traffic thread start\\n\")\n",
    "        time.sleep(2)\n",
    "        rpath = \"/datadrive/lzy/Traffic/\"+self.city+\"/\"+self.city+\"Traffic\"\n",
    "        with open(rpath+'_0.csv', 'w') as fileWriteObj0, open(rpath+'mean.csv', 'w') as fileWriteObj_m, \\\n",
    "        open(rpath+'_1.csv', 'w') as fileWriteObj1, open(rpath+'_2.csv', 'w') as fileWriteObj2, \\\n",
    "        open(rpath+'_3.csv', 'w') as fileWriteObj3, open(rpath+'_4.csv', 'w') as fileWriteObj4, \\\n",
    "        open(rpath+'_5.csv', 'w') as fileWriteObj5, open(rpath+'_6.csv', 'w') as fileWriteObj6:\n",
    "            writer0 = csv.writer(fileWriteObj0, lineterminator='\\n')\n",
    "            writer1 = csv.writer(fileWriteObj1, lineterminator='\\n')\n",
    "            writer2 = csv.writer(fileWriteObj2, lineterminator='\\n')\n",
    "            writer3 = csv.writer(fileWriteObj3, lineterminator='\\n')\n",
    "            writer4 = csv.writer(fileWriteObj4, lineterminator='\\n')\n",
    "            writer5 = csv.writer(fileWriteObj5, lineterminator='\\n')\n",
    "            writer6 = csv.writer(fileWriteObj6, lineterminator='\\n')\n",
    "            writer_m = csv.writer(fileWriteObj_m, lineterminator='\\n')\n",
    "            writer0.writerow(['id','0_4','0_5','0_6','0_7','0_8','0_9','0_10','0_11','0_12','0_13','0_14','0_15','0_16','0_17','0_18','0_19','0_20','0_21','0_22'])\n",
    "            writer1.writerow(['id','1_4','1_5','1_6','1_7','1_8','1_9','1_10','1_11','1_12','1_13','1_14','1_15','1_16','1_17','1_18','1_19','1_20','1_21','1_22'])\n",
    "            writer2.writerow(['id','2_4','2_5','2_6','2_7','2_8','2_9','2_10','2_11','2_12','2_13','2_14','2_15','2_16','2_17','2_18','2_19','2_20','2_21','2_22'])\n",
    "            writer3.writerow(['id','3_4','3_5','3_6','3_7','3_8','3_9','3_10','3_11','3_12','3_13','3_14','3_15','3_16','3_17','3_18','3_19','3_20','3_21','3_22'])\n",
    "            writer4.writerow(['id','4_4','4_5','4_6','4_7','4_8','4_9','4_10','4_11','4_12','4_13','4_14','4_15','4_16','4_17','4_18','4_19','4_20','4_21','4_22'])\n",
    "            writer5.writerow(['id','5_4','5_5','5_6','5_7','5_8','5_9','5_10','5_11','5_12','5_13','5_14','5_15','5_16','5_17','5_18','5_19','5_20','5_21','5_22'])\n",
    "            writer6.writerow(['id','6_4','6_5','6_6','6_7','6_8','6_9','6_10','6_11','6_12','6_13','6_14','6_15','6_16','6_17','6_18','6_19','6_20','6_21','6_22'])\n",
    "            writer_m.writerow(['id','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22'])\n",
    "            while (self.TileCoord_q.empty() is False) or (self.finish_q.empty() is False):\n",
    "                if self.finish_q.empty() is False:\n",
    "                    imginfo = self.finish_q.get()\n",
    "                    #print(imginfo)\n",
    "                    meantraffic = []\n",
    "                    traffic0 = []\n",
    "                    traffic1 = []\n",
    "                    traffic2 = []\n",
    "                    traffic3 = []\n",
    "                    traffic4 = []\n",
    "                    traffic5 = []\n",
    "                    traffic6 = []\n",
    "                    traffic0.append(imginfo[0])\n",
    "                    traffic1.append(imginfo[0])\n",
    "                    traffic2.append(imginfo[0])\n",
    "                    traffic3.append(imginfo[0])\n",
    "                    traffic4.append(imginfo[0])\n",
    "                    traffic5.append(imginfo[0])\n",
    "                    traffic6.append(imginfo[0])\n",
    "                    meantraffic.append(imginfo[0])\n",
    "                    for hour in range(4,23):\n",
    "                        traffic = []\n",
    "                        traffict = []\n",
    "                        for day in range(0,7):\n",
    "                            rootpath = \"/datadrive/lzy/Traffic/\"+self.city+\"/\"+self.city+\"TrafficImg{0}_{1}\".format(day,hour)\n",
    "                            img = cv2.imread(rootpath+imginfo[5], cv2.IMREAD_GRAYSCALE)\n",
    "                            if img is not None:\n",
    "                                gray = img[255-int(imginfo[3]),int(imginfo[4])]\n",
    "                                traffict.append(gray)\n",
    "                                if gray == 105:\n",
    "                                    traffic.append(0.9)\n",
    "                                elif gray == 134:\n",
    "                                    traffic.append(0.7)\n",
    "                                elif gray == 215:\n",
    "                                    traffic.append(0.4)\n",
    "                                else:\n",
    "                                    traffic.append(0.1)\n",
    "                            else:\n",
    "                                traffict.append(255)\n",
    "                                traffic.append(0.1)\n",
    "                        mean = np.mean(traffic)\n",
    "                        traffic0.append(traffict[0])\n",
    "                        traffic1.append(traffict[1])\n",
    "                        traffic2.append(traffict[2])\n",
    "                        traffic3.append(traffict[3])\n",
    "                        traffic4.append(traffict[4])\n",
    "                        traffic5.append(traffict[5])\n",
    "                        traffic6.append(traffict[6])\n",
    "                        meantraffic.append(mean)\n",
    "                    writer_m.writerow(meantraffic)\n",
    "                    writer0.writerow(traffic0)\n",
    "                    writer1.writerow(traffic1)\n",
    "                    writer2.writerow(traffic2)\n",
    "                    writer3.writerow(traffic3)\n",
    "                    writer4.writerow(traffic4)\n",
    "                    writer5.writerow(traffic5)\n",
    "                    writer6.writerow(traffic6)\n",
    "        print(\"traffic thread done\")\n",
    "\n",
    "        \n",
    "    # 线程4： 进度条显示\n",
    "    def pbar(self):\n",
    "        while (self.TileCoord_q.empty() is False) or (self.finish_q.empty() is False) or (self.trafficimg_q.empty() is False):\n",
    "            print(\"Processing: {}/{}, time elapse: {:.0f}s, waiting for imgprocess:{}, waiting for get traffic from img: {}\".format(self.all_lenth-self.TileCoord_q.qsize(), self.all_lenth, time.time()-self.start, self.trafficimg_q.qsize(), self.finish_q.qsize()))\n",
    "            time.sleep(5)\n",
    "\n",
    "    def run(self):\n",
    "        ths =[]\n",
    "\n",
    "        pbar_thread = Thread(target=self.pbar)\n",
    "        pbar_thread.start()\n",
    "        ths.append(pbar_thread)\n",
    "\n",
    "        CoordTiles_thread = Thread(target=self.get_coordTrans)\n",
    "        CoordTiles_thread.start()\n",
    "        ths.append(CoordTiles_thread)\n",
    "\n",
    "        for _ in range(self.thread_num):\n",
    "            producer_thread = Thread(target=self.producer)\n",
    "            producer_thread.start()\n",
    "            ths.append(producer_thread)\n",
    "\n",
    "#         threadPoolimg = ThreadPoolExecutor(max_workers=4, thread_name_prefix=\"img_\")\n",
    "#         process_thread = Thread(target=threadPoolimg.submit(self.imgprocess))\n",
    "#         process_thread.start()\n",
    "#         ths.append(process_thread)\n",
    "        \n",
    "        threadPoolimg = ThreadPoolExecutor(max_workers=3, thread_name_prefix=\"Traffic_\")\n",
    "        traffic_thread = Thread(target=threadPoolimg.submit(self.get_traffics))\n",
    "        traffic_thread.start()\n",
    "        ths.append(traffic_thread)\n",
    "\n",
    "        # 阻塞主线程\n",
    "        for th in ths:\n",
    "            th.join()\n",
    "\n",
    "        print(\"Time consume:\", time.time()-self.start, \"s\")  \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    Spider().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 368676 entries, 0 to 368675\n",
      "Data columns (total 20 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   id      368676 non-null  float64\n",
      " 1   4       368676 non-null  float64\n",
      " 2   5       368676 non-null  float64\n",
      " 3   6       368676 non-null  float64\n",
      " 4   7       368676 non-null  float64\n",
      " 5   8       368676 non-null  float64\n",
      " 6   9       368676 non-null  float64\n",
      " 7   10      368676 non-null  float64\n",
      " 8   11      368676 non-null  float64\n",
      " 9   12      368676 non-null  float64\n",
      " 10  13      368676 non-null  float64\n",
      " 11  14      368676 non-null  float64\n",
      " 12  15      368676 non-null  float64\n",
      " 13  16      368676 non-null  float64\n",
      " 14  17      368676 non-null  float64\n",
      " 15  18      368676 non-null  float64\n",
      " 16  19      368676 non-null  float64\n",
      " 17  20      368676 non-null  float64\n",
      " 18  21      368676 non-null  float64\n",
      " 19  22      368676 non-null  float64\n",
      "dtypes: float64(20)\n",
      "memory usage: 56.3 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 736629 entries, 0 to 736628\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   id           736629 non-null  int64  \n",
      " 1   Coordpairid  736629 non-null  int64  \n",
      " 2   rid          736629 non-null  int64  \n",
      " 3   rfclass      736629 non-null  object \n",
      " 4   lng          736629 non-null  float64\n",
      " 5   lat          736629 non-null  float64\n",
      " 6   code         736629 non-null  int64  \n",
      " 7   Coordpair    736629 non-null  object \n",
      " 8   dem          736467 non-null  float64\n",
      " 9   slope        689575 non-null  float64\n",
      " 10  aspect       689575 non-null  float64\n",
      "dtypes: float64(5), int64(4), object(2)\n",
      "memory usage: 61.8+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 736630 entries, 0 to 736629\n",
      "Data columns (total 30 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   id           736630 non-null  int64  \n",
      " 1   Coordpairid  736630 non-null  int64  \n",
      " 2   rid          736630 non-null  int64  \n",
      " 3   rfclass      736630 non-null  object \n",
      " 4   lng          736630 non-null  float64\n",
      " 5   lat          736630 non-null  float64\n",
      " 6   code         736630 non-null  int64  \n",
      " 7   Coordpair    736630 non-null  object \n",
      " 8   dem          736468 non-null  float64\n",
      " 9   slope        689576 non-null  float64\n",
      " 10  aspect       689576 non-null  float64\n",
      " 11  4            368676 non-null  float64\n",
      " 12  5            368676 non-null  float64\n",
      " 13  6            368676 non-null  float64\n",
      " 14  7            368676 non-null  float64\n",
      " 15  8            368676 non-null  float64\n",
      " 16  9            368676 non-null  float64\n",
      " 17  10           368676 non-null  float64\n",
      " 18  11           368676 non-null  float64\n",
      " 19  12           368676 non-null  float64\n",
      " 20  13           368676 non-null  float64\n",
      " 21  14           368676 non-null  float64\n",
      " 22  15           368676 non-null  float64\n",
      " 23  16           368676 non-null  float64\n",
      " 24  17           368676 non-null  float64\n",
      " 25  18           368676 non-null  float64\n",
      " 26  19           368676 non-null  float64\n",
      " 27  20           368676 non-null  float64\n",
      " 28  21           368676 non-null  float64\n",
      " 29  22           368676 non-null  float64\n",
      "dtypes: float64(24), int64(4), object(2)\n",
      "memory usage: 174.2+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "city = 'BJ'\n",
    "df_info = pd.read_csv('/datadrive/lzy/Traffic/'+city+\"/\"+city+'PtDB.csv',names = [\"id\",\"Coordpairid\",\"rid\",\"rfclass\",\"lng\",\"lat\",\"code\",\"Coordpair\",\"dem\",\"slope\",\"aspect\"])\n",
    "df_T = pd.read_csv('/datadrive/lzy/Traffic/'+city+\"/\"+city+'Trafficmean.csv')\n",
    "df_T.info()\n",
    "df_info.info()\n",
    "df_T[\"id\"] = df_T[\"id\"].astype(int)\n",
    "for i in range(4,23):\n",
    "    df_T[str(i)] = df_T[str(i)].map(lambda x: 1-x)\n",
    "df = pd.merge(df_info,df_T,on = \"id\",how = \"left\")\n",
    "df.info()\n",
    "trans={\"4\":1,\"5\":1,\"6\":0.9,\"7\":0.9,\"8\":0.9,\"9\":0.9,\"10\":0.9,\"11\":0.9,\"12\":0.9,\"13\":0.9,\"14\":0.9,\"15\":0.9,\"16\":0.9,\"17\":0.9,\"18\":0.9,\"19\":0.9,\"20\":0.9,\"21\":0.9,\"22\":0.9}\n",
    "df = df.fillna(value=trans)\n",
    "df = df.fillna(axis=0,method='ffill')\n",
    "df_out = df.iloc[:,[0,2,3,4,5,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29]]\n",
    "# df.columns = [\"pid\",\"Coordpair\",\"rfid\",\"interval\",\"rfid_2\",\"rid\",\"code\",\"rfclass\",\"name\",\"ref\",\"oneway\",\"maxspeed\",\"layer\",\"bridge\",\"tunnel\",\"lng\",\"lat\",\"dem\",\"slope\",\"aspect\"]\n",
    "df_out.to_csv('/datadrive/lzy/Traffic/'+city+\"/\"+city+'AllTraffic.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rid</th>\n",
       "      <th>rfclass</th>\n",
       "      <th>lng</th>\n",
       "      <th>lat</th>\n",
       "      <th>dem</th>\n",
       "      <th>slope</th>\n",
       "      <th>aspect</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>...</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4231222</td>\n",
       "      <td>primary</td>\n",
       "      <td>116.389467</td>\n",
       "      <td>39.905764</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2.865651</td>\n",
       "      <td>118.064003</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4231222</td>\n",
       "      <td>primary</td>\n",
       "      <td>116.389489</td>\n",
       "      <td>39.905265</td>\n",
       "      <td>33.0</td>\n",
       "      <td>7.793719</td>\n",
       "      <td>129.341599</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4231222</td>\n",
       "      <td>primary</td>\n",
       "      <td>116.389511</td>\n",
       "      <td>39.904765</td>\n",
       "      <td>22.0</td>\n",
       "      <td>12.489513</td>\n",
       "      <td>122.537949</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4231222</td>\n",
       "      <td>primary</td>\n",
       "      <td>116.389532</td>\n",
       "      <td>39.904266</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.220832</td>\n",
       "      <td>94.299652</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4231222</td>\n",
       "      <td>primary</td>\n",
       "      <td>116.389554</td>\n",
       "      <td>39.903766</td>\n",
       "      <td>21.0</td>\n",
       "      <td>8.070035</td>\n",
       "      <td>56.693130</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736625</th>\n",
       "      <td>736625</td>\n",
       "      <td>641311622</td>\n",
       "      <td>unclassified</td>\n",
       "      <td>116.179974</td>\n",
       "      <td>40.219456</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1.638770</td>\n",
       "      <td>172.411743</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736626</th>\n",
       "      <td>736626</td>\n",
       "      <td>641311622</td>\n",
       "      <td>unclassified</td>\n",
       "      <td>116.180108</td>\n",
       "      <td>40.218974</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.547748</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736627</th>\n",
       "      <td>736627</td>\n",
       "      <td>641311622</td>\n",
       "      <td>unclassified</td>\n",
       "      <td>116.180241</td>\n",
       "      <td>40.218492</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.547748</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736628</th>\n",
       "      <td>736628</td>\n",
       "      <td>641311622</td>\n",
       "      <td>unclassified</td>\n",
       "      <td>116.182446</td>\n",
       "      <td>40.222260</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.362908</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736629</th>\n",
       "      <td>736629</td>\n",
       "      <td>641311622</td>\n",
       "      <td>unclassified</td>\n",
       "      <td>116.180258</td>\n",
       "      <td>40.218430</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.362908</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>736630 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id        rid       rfclass         lng        lat   dem  \\\n",
       "0            1    4231222       primary  116.389467  39.905764  38.0   \n",
       "1            2    4231222       primary  116.389489  39.905265  33.0   \n",
       "2            3    4231222       primary  116.389511  39.904765  22.0   \n",
       "3            4    4231222       primary  116.389532  39.904266  17.0   \n",
       "4            5    4231222       primary  116.389554  39.903766  21.0   \n",
       "...        ...        ...           ...         ...        ...   ...   \n",
       "736625  736625  641311622  unclassified  116.179974  40.219456  63.0   \n",
       "736626  736626  641311622  unclassified  116.180108  40.218974  61.0   \n",
       "736627  736627  641311622  unclassified  116.180241  40.218492  61.0   \n",
       "736628  736628  641311622  unclassified  116.182446  40.222260  67.0   \n",
       "736629  736629  641311622  unclassified  116.180258  40.218430  61.0   \n",
       "\n",
       "            slope      aspect    4    5  ...   13   14   15   16   17   18  \\\n",
       "0        2.865651  118.064003  0.9  0.9  ...  0.9  0.9  0.9  0.9  0.9  0.9   \n",
       "1        7.793719  129.341599  0.9  0.9  ...  0.9  0.9  0.9  0.9  0.9  0.9   \n",
       "2       12.489513  122.537949  0.9  0.9  ...  0.9  0.9  0.9  0.9  0.9  0.9   \n",
       "3       10.220832   94.299652  0.9  0.9  ...  0.9  0.9  0.9  0.9  0.9  0.9   \n",
       "4        8.070035   56.693130  0.9  0.9  ...  0.9  0.9  0.9  0.9  0.9  0.9   \n",
       "...           ...         ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "736625   1.638770  172.411743  1.0  1.0  ...  0.9  0.9  0.9  0.9  0.9  0.9   \n",
       "736626   0.547748  180.000000  1.0  1.0  ...  0.9  0.9  0.9  0.9  0.9  0.9   \n",
       "736627   0.547748  180.000000  1.0  1.0  ...  0.9  0.9  0.9  0.9  0.9  0.9   \n",
       "736628   0.362908   45.000000  1.0  1.0  ...  0.9  0.9  0.9  0.9  0.9  0.9   \n",
       "736629   0.362908   45.000000  1.0  1.0  ...  0.9  0.9  0.9  0.9  0.9  0.9   \n",
       "\n",
       "         19   20   21   22  \n",
       "0       0.9  0.9  0.9  0.9  \n",
       "1       0.9  0.9  0.9  0.9  \n",
       "2       0.9  0.9  0.9  0.9  \n",
       "3       0.9  0.9  0.9  0.9  \n",
       "4       0.9  0.9  0.9  0.9  \n",
       "...     ...  ...  ...  ...  \n",
       "736625  0.9  0.9  0.9  0.9  \n",
       "736626  0.9  0.9  0.9  0.9  \n",
       "736627  0.9  0.9  0.9  0.9  \n",
       "736628  0.9  0.9  0.9  0.9  \n",
       "736629  0.9  0.9  0.9  0.9  \n",
       "\n",
       "[736630 rows x 27 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/datadrive/lzy/Pano/BJBSV/BJBSV2_p_pano\n",
      "/datadrive/lzy/Pano/BJBSV/BJBSV3_p_pano\n",
      "/datadrive/lzy/Pano/BJBSV/BJBSV4_p_pano\n",
      "/datadrive/lzy/Pano/BJBSV/BJBSV6_p_pano\n"
     ]
    }
   ],
   "source": [
    "# --coding:utf-8\n",
    "# @author:Liu Ziyu\n",
    "# Date:2020-04-22\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.image as mpimg \n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import csv\n",
    "\n",
    "SConst = 1367\n",
    "beta = 0.5\n",
    "Div_skyazi = 16\n",
    "day = [31,28,31,30,31,30,31,31,30,31,30,31]\n",
    "# optical air mass from Smithsonian meteorological tables v.114\n",
    "m_thita = [5.6,6.18,6.88,7.77,8.9,10.39,12.44,15.36,19.79,26.96]\n",
    "\n",
    "# get all pano files under a rootpath\n",
    "def get_allpano(cwd):\n",
    "    result = []\n",
    "    get_dir = os.listdir(cwd)  \n",
    "    for i in get_dir:          \n",
    "        sub_dir = os.path.join(cwd,i)  \n",
    "        if os.path.isdir(sub_dir):     \n",
    "            if sub_dir.endswith(\"_pano\"):\n",
    "                result.append(i)\n",
    "    return result\n",
    "\n",
    "\n",
    "# get all BSV files under a rootpath\n",
    "def get_allBSV(cwd):\n",
    "    result = []\n",
    "    get_dir = os.listdir(cwd)  \n",
    "    for i in get_dir:          \n",
    "        sub_dir = os.path.join(cwd,i)  \n",
    "        if os.path.isdir(sub_dir):     \n",
    "            if sub_dir.endswith(\"BSV\"):\n",
    "                result.append(i)\n",
    "    return result\n",
    "\n",
    "# get all img under a rootpath\n",
    "def get_allimg(cwd):\n",
    "    paths = glob.glob(os.path.join(cwd, '*.png'))\n",
    "    paths.sort()\n",
    "    return paths\n",
    "\n",
    "\n",
    "# extract the roadid, lat, lon from the imgname and return as array\n",
    "def get_write_imginfo(imgname):\n",
    "    imgname = imgname.rsplit('/',1)[1]\n",
    "    temp = imgname.split('_')\n",
    "    roadid = temp[0]\n",
    "    lat = temp[1]\n",
    "    lng = temp[2].rsplit('.',1)[0]\n",
    "    return [roadid,lat,lng]\n",
    "\n",
    "\n",
    "#split sunmaparr for center points in a year by month\n",
    "def split_sunmaparr_c(sunmaparr_cpath):\n",
    "    sunmaparr_c = np.loadtxt(sunmaparr_cpath,dtype=np.float,delimiter=',',encoding='utf-8')\n",
    "    # split the sunmap by months\n",
    "    intervalarrm = np.arange(2,13,1)\n",
    "    split_atmc = sunmaparr_c[:, 0].searchsorted(intervalarrm)\n",
    "    sunmaparr_c = np.split(sunmaparr_c, split_atmc)\n",
    "    return sunmaparr_c\n",
    "\n",
    "def split_skymaparr(skymap_path):\n",
    "    skymaparr = np.loadtxt(skymap_path,dtype=np.float,delimiter=',',encoding='utf-8',skiprows=1)\n",
    "    # split the sunmap by months\n",
    "    intervalarrm = np.arange(1,128,1)\n",
    "    split_at = skymaparr[:, 1].searchsorted(intervalarrm)\n",
    "    skymaparr = np.split(skymaparr, split_at)\n",
    "    return skymaparr\n",
    "\n",
    "#split sunmaparr for each hour interval in a year by month and day hour   \n",
    "def split_sunmaparr_y(sunmaparr_ypath):\n",
    "    sunmaparr_y = np.loadtxt(sunmaparr_ypath,dtype=np.float,delimiter=',',encoding='utf-8',skiprows=1)\n",
    "    intervalarrm = np.arange(2,13,1)\n",
    "    split_atmy = sunmaparr_y[:, 0].searchsorted(intervalarrm)\n",
    "    sunmaparr_y = np.array(np.split(sunmaparr_y, split_atmy))\n",
    "    # split the sunmap by hour interval\n",
    "    for i in range(0,len(sunmaparr_y)):\n",
    "        # get the sunrise and sunset time for each day\n",
    "        maxh = sunmaparr_y[i][:,3].max()\n",
    "        minh = sunmaparr_y[i][:,3].min()\n",
    "        # print(minh,maxh)\n",
    "        if math.modf(maxh)[0] > 0.5:\n",
    "            maxh = round(maxh)\n",
    "        elif math.modf(maxh)[0] < 0.5:\n",
    "            maxh = math.ceil(maxh)-0.5\n",
    "        if math.modf(minh)[0] > 0.5:\n",
    "            minh = round(minh)\n",
    "        elif math.modf(minh)[0] < 0.5:\n",
    "            minh = round(minh) + 0.5\n",
    "        else:\n",
    "            minh = minh + 0.5\n",
    "        # sort the array by hour inter\n",
    "        intervalarr = np.arange(minh, maxh, 0.5, dtype = float)\n",
    "        temparr = np.array(sorted(sunmaparr_y[i],key=lambda x:(x[3])))\n",
    "        split_ath = temparr[:, 3].searchsorted(intervalarr)\n",
    "        sunmaparr_y[i] = np.split(temparr, split_ath)\n",
    "#         print(sunmaparr_y[i])\n",
    "    return sunmaparr_y\n",
    "\n",
    "\n",
    "def get_gap(img,sunmapy_arr,hour_interval):\n",
    "    blue_rgb = np.array([6, 230, 230],dtype = np.float)\n",
    "    gap_sunmap = []\n",
    "    hour_sundur = np.empty((len(sunmapy_arr)), dtype = np.float)\n",
    "    for j in range(0,len(sunmapy_arr)):\n",
    "#         print(len(sunmapy_arr))\n",
    "        sundur = 0.0\n",
    "        hour_gaparr = np.empty((len(sunmapy_arr[j])), dtype = np.float)\n",
    "        for k in range(0,len(sunmapy_arr[j])):\n",
    "#             print(len(sunmapy_arr[j]))\n",
    "            count = 0\n",
    "            ptnum = sunmapy_arr[j][k].shape[0]\n",
    "            for pt in range(0,ptnum):\n",
    "                x = int(sunmapy_arr[j][k][pt][9])\n",
    "                y = int(sunmapy_arr[j][k][pt][10])\n",
    "                if((image[x-1][y-1]*255 == blue_rgb).all()):\n",
    "                    count += 1\n",
    "            #print(count,ptnum)\n",
    "            hour_gaparr[k] = count / ptnum * 1.0\n",
    "            sundur += hour_gaparr[k] * hour_interval * len(sunmapy_arr[j])\n",
    "        gap_sunmap.append(hour_gaparr)\n",
    "        hour_sundur[j] = sundur\n",
    "    return gap_sunmap, hour_sundur\n",
    "\n",
    "\n",
    "def get_skygap(img,skymap_arr):\n",
    "    blue_rgb = np.array([6, 230, 230],dtype = np.float)\n",
    "    gap_skymap = []\n",
    "#     hour_sundur = np.empty((len(sunmapy_arr)), dtype = np.float)\n",
    "    for j in range(0,len(skymap_arr)):\n",
    "        count = 0\n",
    "        ptnum = skymap_arr[j].shape[0]\n",
    "        for pt in range(0,ptnum): \n",
    "            x = int(skymap_arr[j][pt][4])\n",
    "            y = int(skymap_arr[j][pt][5])\n",
    "            if((image[x-1][y-1]*255 == blue_rgb).all()):\n",
    "                count += 1\n",
    "            #print(count,ptnum)\n",
    "        gap_skymap.append(count / ptnum * 1.0)\n",
    "    return gap_skymap\n",
    "\n",
    "\n",
    "def deg2rad_G(data):\n",
    "    if data == '':\n",
    "        data = 0\n",
    "    else:\n",
    "        data = math.radians(float(data))\n",
    "    return data\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\": \n",
    "    city = ['BJ','YA','TM','ZJ','SH','CD','BS','BJ','CQ','AL','FCG','JL','CD','JQ','NJZ','LS','QQHE','XA','ZT','HEB','HZ','SZ','TM','MDJ','SH','WH']\n",
    "    cityi = 0\n",
    "    # AL_30.3_81.1sunmapcenter.csv fcg_21.7_108.4sunmapcenter.csv JL_43.9_126.6sunmapcenter.csv CD_30.6_104.1sunmap.csv\n",
    "    # JQ_39.7_98.5sunmap.csv NJZ_25.8_98.9sunmap.csv LS_29.7_91.1sunmap.csv QQHE_47.4_123.9sunmap XA_34.3_108.9sunmap.csv\n",
    "    # ZJ_21.3_110.4sunmap ZT_27.3_103.7sunmap.csv HEB_45.8_126.5sunmap.csv HZ_24.4_111.6sunmap.csv SZ_22.5_114.1sunmap.csv\n",
    "    # TM_30.7_113.2sunmap.csv MDJ_44.6_129.6sunmap.csv SH_31.2_121.1sunmap.csv CQ_29.5_106.5sunmap BJ_39.9_115.2sunmap\n",
    "    # BS_42_126.4sunmap.csv YA_30_103.1sunmap\n",
    "    rootpath = '/datadrive/lzy/Pano/'\n",
    "    trafficpath = '/datadrive/lzy/Traffic/'+city[cityi]+'/'+city[cityi]+'AllTraffic.csv'\n",
    "    cloudpath = '/datadrive/lzy/Traffic/'+city[cityi]+'/'+city[cityi]+'cloudy.csv'\n",
    "    skymappath = '/datadrive/lzy/skymap_az.csv'\n",
    "    outpath = '/datadrive/lzy/R_new/'\n",
    "    data = np.loadtxt(trafficpath,dtype=np.str,delimiter=',',encoding='utf-8')\n",
    "    cloudy =  np.loadtxt(cloudpath,dtype=np.str,delimiter=',',encoding='utf-8')\n",
    "    # read the sunmap for centerpoint and all for given time interval like 0.05\n",
    "    sunmapc_path = '/datadrive/lzy/Traffic/'+city[cityi]+'/BJ_39.9_115.2sunmapcenter.csv'\n",
    "    sunmapy_path = '/datadrive/lzy/Traffic/'+city[cityi]+'/BJ_39.9_115.2sunmap.csv'\n",
    "    sunmapc_arr = split_sunmaparr_c(sunmapc_path)\n",
    "    sunmapy_arr = split_sunmaparr_y(sunmapy_path)\n",
    "    skymap_arr = split_skymaparr(skymappath)\n",
    "    sky_num = len(skymap_arr)\n",
    "    \n",
    "    # skymap: weight the proportion of diffuse radiation originating in a given sky sector relative to all sectors \n",
    "    skyweight_arr = []\n",
    "    # the thita and azimuth of center point for each sector\n",
    "    skythitac_arr = []\n",
    "    skyazimuthc_arr = []\n",
    "    for nsector in range(0,sky_num):\n",
    "        thita_max = np.max(skymap_arr[nsector][:,15])\n",
    "        thita_min = np.min(skymap_arr[nsector][:,15])\n",
    "        thita_avg = np.mean(skymap_arr[nsector][:,15])\n",
    "        azimuth_avg = np.mean(skymap_arr[nsector][:,16])\n",
    "        # Weightθ,α = (cosθ2- cosθ1) / Divazi    (7)\n",
    "        skyweight = (math.cos(math.radians(thita_min))-math.cos(math.radians(thita_max)))/Div_skyazi\n",
    "        skyweight_arr.append(skyweight)\n",
    "        skythitac_arr.append(math.radians(thita_avg))\n",
    "        skyazimuthc_arr.append(math.radians(azimuth_avg))          \n",
    "    \n",
    "#     BSVfile = get_allBSV(rootpath)\n",
    "    BSVfile = ['BJBSV']\n",
    "    for rootf in BSVfile:\n",
    "        panopath = rootpath + rootf\n",
    "        outname = outpath + rootf + '_r.csv'\n",
    "        outfile = open(outname, 'w' , newline=\"\")\n",
    "        writer = csv.writer(outfile, lineterminator='\\n')\n",
    "        writer.writerow(['fid','roadid','roadtype','lat','lng','edm','slope','aspect','dir_nt','dir_weighted','dif_nt','dif_weighted','total_nt','total_weighted'])\n",
    "        panofile = get_allpano(panopath)\n",
    "        for panof in panofile:\n",
    "            imgpath = panopath + '/' + panof\n",
    "            print(imgpath)\n",
    "            imgname = get_allimg(imgpath)\n",
    "#             imgname = get_allimg(\"/datadrive/urbanplayground/Streetview/SegDone/ALBSV/SegPic/ALBSV5_p_pano\")\n",
    "            # sparse image name\n",
    "            for img in imgname:\n",
    "                #print(data)\n",
    "                imginfo = get_write_imginfo(img)\n",
    "                f_id = int(imginfo[0])\n",
    "                image = mpimg.imread(img)\n",
    "                #plt.imshow(image)\n",
    "                #plt.show()\n",
    "                result = get_gap(image,sunmapy_arr,0.5)\n",
    "                gap_sunmap = result[0]\n",
    "#                 print(gap_sunmap)\n",
    "                sundur_img = result[1]\n",
    "                gap_sky = get_skygap(image,skymap_arr)\n",
    "                # get the elevation of this image\n",
    "                Elev = data[f_id,5]\n",
    "                if Elev == '' or Elev == -1:\n",
    "                    Elev = float(data[f_id-1,5])\n",
    "                else:\n",
    "                    Elev = float(Elev)\n",
    "                # print(data[f_id,5])\n",
    "                # Elev = float(data[f_id,5])\n",
    "                # slope Gz aspect Ga\n",
    "                Gz = deg2rad_G(data[f_id,6])\n",
    "                Ga = deg2rad_G(data[f_id,7])\n",
    "                # m(θ) is the relative optical path length\n",
    "                mz_y = []\n",
    "                AngIn_y = []\n",
    "                # every sector Direct radiation workday\n",
    "                Dir_ywork = []\n",
    "                # each month of the total direct radiation workday\n",
    "                Dir_monwork = []\n",
    "                # the total direct of the year workday\n",
    "                Dir_allwork = 0\n",
    "                # for weekend\n",
    "                Dir_ywkend = []\n",
    "                Dir_monwkend = []\n",
    "                Dir_allwkend = 0\n",
    "                # without traffic\n",
    "                Dir_yntraff = []\n",
    "                Dir_monntraff = []\n",
    "                Dir_allntraff = 0\n",
    "                # weighted\n",
    "                Dir_yweighted = []\n",
    "                Dir_monweighted = []\n",
    "                Dir_allweighted = 0\n",
    "                # for diffuse radiation\n",
    "                Rglb_work = 0\n",
    "                Rglb_wkend = 0\n",
    "                Rglb_ntraff = 0\n",
    "                Rglb_weighted = 0\n",
    "                for mon in range(0,len(sunmapc_arr)): \n",
    "                    Pdif = float(cloudy[mon][1])\n",
    "                    mz_m = []\n",
    "                    AngIn = []\n",
    "                    # dir \n",
    "                    Dir_work = []\n",
    "                    Dir_wkend = []\n",
    "                    Dir_ntraff = []\n",
    "                    Dir_weighted = []\n",
    "                    # dir month tempt workday\n",
    "                    Dir_monworkt = 0\n",
    "                    Dir_monwkendt = 0\n",
    "                    Dir_monntrafft = 0\n",
    "                    Dir_monweightedt = 0\n",
    "                    for num in range(0,len(sunmapc_arr[mon])):\n",
    "                        thita = math.radians(90-sunmapc_arr[mon][num][2])\n",
    "                        alfa = math.radians(sunmapc_arr[mon][num][3])\n",
    "                        hournow = int(math.floor(sunmapc_arr[mon][num][1]))\n",
    "#                         if hournow < 5 :\n",
    "#                             hournow = 5\n",
    "#                         elif hournow > 20:\n",
    "#                             hournow = 20\n",
    "                        # two calculate methods by thita copared to 80 degree\n",
    "                        if thita < 80:\n",
    "                            # For zenith angles less than 80 degree,\n",
    "                            # m(θ) = EXP(-0. 000118 * Elev - 1. 638 * 10^-9 * Elev^2) /cos(θ)\n",
    "                            mz_t = math.exp(-0.000118 * Elev - 1.638 * math.pow(10,-9) * math.pow(Elev,2))/math.cos(thita)\n",
    "                        else:\n",
    "                            # get from \n",
    "                            index = int(round(thita))-80\n",
    "                            if index == 10:\n",
    "                                mz_t = m_thita[9]\n",
    "                            else:\n",
    "                                mz_t = m_thita[index]\n",
    "                        # Angle of incidence (AngInSky θ,α) between the intercepting surface and a given sky sector with a centroid at zenith angle θ and azimuth angle α\n",
    "                        # AngIn θ,α = acos[Cos(θ)*Cos(Gz)+Sin(θ)*Sin(Gz)*Cos(α-Ga)]\n",
    "                        angin_t = math.acos(math.cos(thita)*math.cos(Gz)+math.sin(thita)*math.sin(Gz)*abs(math.cos(alfa-Ga)))\n",
    "                        # calculate Direct rdiation\n",
    "                        # Dirθ,α = SConst * β^m(θ) * SunDurθ,α * SunGapθ,α * cos(AngInθ,α)\n",
    "                        gap_count = len(gap_sunmap[mon])\n",
    "                        if num == gap_count or num > gap_count:\n",
    "                            gap_tem = gap_sunmap[mon][gap_count-1]\n",
    "                        else:\n",
    "                            gap_tem = gap_sunmap[mon][num]\n",
    "                        Dir_ntrafft = SConst * math.pow(beta,mz_t) * day[mon]*0.5 * gap_tem * math.cos(angin_t)*(1-Pdif)\n",
    "                        Dir_weightedt = Dir_ntrafft * float(data[f_id,4+hournow])\n",
    "#                         Dir_workt = Dir_ntrafft * float(data[f_id,3+hournow])\n",
    "#                         Dir_wkendt = Dir_ntrafft * float(data[f_id,19+hournow])\n",
    "#                         Dir_weightedt = Dir_workt * 5/7 + Dir_wkendt * 2/7\n",
    "#                         Dir_monworkt += Dir_workt\n",
    "#                         Dir_monwkendt += Dir_wkendt\n",
    "                        Dir_monntrafft += Dir_ntrafft\n",
    "                        Dir_monweightedt += Dir_weightedt\n",
    "                        mz_m.append(mz_t)\n",
    "#                         mz_sum += mz_t * Pdif * day[mon] * 0.5\n",
    "                        # prepare for diffuse radiation for Rglb\n",
    "                        # Rglb = (SConst Σ(βm(θ))) / (1 - Pdif)\n",
    "                        Rglb_ntrafft = SConst * math.pow(beta,mz_t) * Pdif * 0.5 / (1-Pdif)\n",
    "                        Rglb_weightedt = Rglb_ntrafft * float(data[f_id,4+hournow])\n",
    "#                         Rglb_workt = Rglb_ntrafft * float(data[f_id,4+hournow])\n",
    "#                         Rglb_wkendt = Rglb_ntrafft * float(data[f_id,19+hournow])\n",
    "                        Rglb_ntraff += Rglb_ntrafft\n",
    "#                         Rglb_work += Rglb_workt\n",
    "#                         Rglb_wkend += Rglb_wkendt\n",
    "                        Rglb_weighted += Rglb_weightedt\n",
    "                        AngIn.append(angin_t)\n",
    "                        Dir_ntraff.append(Dir_ntrafft)\n",
    "#                         Dir_work.append(Dir_workt)\n",
    "#                         Dir_wkend.append(Dir_wkendt)\n",
    "                        Dir_weighted.append(Dir_weightedt)\n",
    "                    Dir_yntraff.append(Dir_ntraff)\n",
    "#                     Dir_ywork.append(Dir_work)\n",
    "#                     Dir_ywkend.append(Dir_wkend)\n",
    "                    Dir_yweighted.append(Dir_weighted)\n",
    "#                     Dir_monwork.append(Dir_monworkt)\n",
    "                    Dir_allntraff += Dir_monntrafft\n",
    "#                     Dir_allwork += Dir_monworkt\n",
    "#                     Dir_allwkend += Dir_monwkendt\n",
    "                    Dir_allweighted += Dir_monweightedt\n",
    "                    mz_y.append(mz_m)\n",
    "                    AngIn_y.append(AngIn)\n",
    "#                 Rglb_weighted = Rglb_work * 5/7 + Rglb_wkend *2/7\n",
    "#                 print('Dir:',Dir_allntraff,Dir_allwork,Dir_allwkend,Dir_allweighted)\n",
    "#                 print(\"Rglb:\",Rglb_ntraff,Rglb_work,Rglb_wkend,Rglb_weighted)\n",
    "                skyAngIn = []\n",
    "                #  Difθ,α = Rglb * Pdif * Dur * SkyGapθ,α * Weightθ,α * cos(AngInθ,α) \n",
    "                Dif_secntraff = []\n",
    "#                 Dif_secwork = []\n",
    "#                 Dif_secwkend = []\n",
    "                Dif_secweighted = []\n",
    "                Dif_sumntraff = 0\n",
    "#                 Dif_sumwork = 0\n",
    "#                 Dif_sumwkend = 0\n",
    "                Dif_sumweighted = 0\n",
    "                for nsec in range(0,sky_num):\n",
    "                    sky_thita = skythitac_arr[nsec]\n",
    "                    skyangin_t = math.acos(math.cos(sky_thita)*math.cos(Gz)+math.sin(sky_thita)*math.sin(Gz)*abs(math.cos(skyazimuthc_arr[nsec]-Ga)))\n",
    "                    tempt = gap_sky[nsec] * skyweight_arr[nsec] * math.cos(skyangin_t)\n",
    "#                     print(Rglb_ntraff,gap_sky[nsec],skyweight_arr[nsec],math.cos(skyangin_t))\n",
    "#                     time.sleep(1)\n",
    "                    Dif_ntrafft = Rglb_ntraff * tempt\n",
    "#                     Dif_workt = Rglb_work * tempt\n",
    "#                     Dif_wkendt = Rglb_wkend * tempt\n",
    "                    Dif_weightedt = Rglb_weighted * tempt\n",
    "                    skyAngIn.append(skyangin_t)\n",
    "                    Dif_secntraff.append(Dif_ntrafft)\n",
    "#                     Dif_secwork.append(Dif_workt)\n",
    "#                     Dif_secwkend.append(Dif_wkendt)\n",
    "                    Dif_secweighted.append(Dif_weightedt)\n",
    "                    Dif_sumntraff += Dif_ntrafft\n",
    "#                     Dif_sumwork += Dif_workt\n",
    "#                     Dif_sumwkend += Dif_wkendt\n",
    "                    Dif_sumweighted += Dif_weightedt\n",
    "#                 print('Dif:',Dif_sumntraff,Dif_sumwork,Dif_sumwkend,Dif_sumweighted)\n",
    "                writer.writerow([f_id,data[f_id,1],data[f_id,2],imginfo[1],imginfo[2],Elev,data[f_id,6],data[f_id,7],\n",
    "                                 Dir_allntraff,Dir_allweighted,Dif_sumntraff,Dif_sumweighted,\n",
    "                                 Dir_allntraff+Dif_sumntraff,Dir_allweighted+Dif_sumweighted])\n",
    "        outfile.close()\n",
    "        print('finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
